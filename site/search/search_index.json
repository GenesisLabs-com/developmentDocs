{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Development Docs Development docs help how to configure colors project from cosmos. How to make changes and in open source gaia and cosmos sdk project. colors Hub","title":"welcome"},{"location":"#development-docs","text":"Development docs help how to configure colors project from cosmos. How to make changes and in open source gaia and cosmos sdk project.","title":"Development Docs"},{"location":"#colors-hub","text":"","title":"colors Hub"},{"location":"Setup-Kubernetes/","text":"Up a Kubernetes Cluster on AWS in 5 Minutes Kubernetes is like magic. It is a system for working with containerized applications: deployment, scaling, management, service discovery, magic. Think Docker at scale with little hassle. Despite the power of Kubernetes though, I find the official guide for setting up Kubernetes on AWS a bit overwhelming, so I wrote a simpler version to get started. As a side note, AWS introduced a new serviced called A mazon Elastic Container Service for Kubernetes \u2013 EKS for short. But it\u2019s still in Preview mode. Before we begin, here\u2019s a YouTube video demonstrating how to set up a Kubernetes Cluster on AWS following the instructions below: Prerequisites Before setting up the Kubernetes cluster, you\u2019ll need an AWS account and an installation of the AWS Command Line Interface . Make sure to configure the AWS CLI to use your access key ID and secret access key: aws configure AWS Access Key ID [None]: your aws access key AWS Secret Access Key [None]: your aws secret key Default region name [None]: us-east-1 Default output format [None]: Installing kops + kubectl Now, to get started, let\u2019s install two Kubernetes CLI utilities: Kubernetes Operations, kops Kubernetes command-line tool, kubectl On Mac OS X, we\u2019ll use brew to install. If you\u2019re on Linux, see the official Kops installation guide. Setting Up the Kubernetes Cluster Easy enough. Now, let\u2019s set up the Kubernetes cluster. The first thing we need to do is create an S3 bucket for kops to use to store the state of the Kubernetes cluster and its configuration. We\u2019ll use the bucket name colors-kops-state-store. $ aws s3api create-bucket --bucket colors-kops-state-store --region us-east-2 --create-bucket-configuration LocationConstraint=us-east-2 After creating the colors-kops-state-store bucket, let\u2019s enable versioning to revert or recover a previous state store. $ aws s3api put-bucket-versioning --bucket colors-kops-state-store --versioning-configuration Status=Enabled Before creating the cluster, let\u2019s set two environment variables: KOPS_CLUSTER_NAME and KOPS_STATE_STORE. For safe keeping you should add the following to your ~/.bash_profile or ~/.bashrc configs (or whatever the equivalent is if you don\u2019t use bash). export KOPS_CLUSTER_NAME=colors.k8s.local export KOPS_STATE_STORE=s3://colors-kops-state-store kops export kubecfg --state s3://colors-kops-state-store --name=colors.k8s.local You don\u2019t HAVE TO set the environment variables, but they are useful and referenced by kops commands. For example, see kops create cluster --help . If the the Kubernetes cluster name ends with k8s.local, Kubernetes will create a gossip-based cluster. Now, to generate the cluster configuration: $ kops create cluster --node-count=1 --node-size=t2.medium --zones=us-east-2b Note: this line doesn\u2019t launch the AWS EC2 instances. It simply creates the configuration and writes to the s3://colors-kops-state-store bucket we created above. In our example, we\u2019re creating 2 t2.medium EC2 work nodes in addition to a c4.large master instance (default). $ kops edit cluster Alternatively, you can name the cluster by appending --name to the command: $ kops create cluster --node-count=1 --node-size=t2.medium --zones=us-east-1a --name chubby-bunnies Now that we\u2019ve generated a cluster configuration, we can edit its description before launching the instances. The config is loaded from s3://colors-kops-state-store. You can change the editor used to edit the config by setting $EDITOR or $KUBE_EDITOR. For instance, in my ~/.bashrc, I have export KUBE_EDITOR=emacs. Time to build the cluster. This takes a few minutes to boot the EC2 instances and download the Kubernetes components. kops update cluster --name ${KOPS_CLUSTER_NAME} --yes After waiting a bit, let\u2019s validate the cluster to ensure the master + 2 nodes have launched. $ kops validate cluster Validating cluster colors.k8s.local INSTANCE GROUPS NAME ROLE MACHINETYPE MIN MAX SUBNETS master-us-east-1a Master c4.large 1 1 us-east-1a nodes Node t2.medium 2 2 us-east-1a NODE STATUS NAME ROLE READY ip-172-20-34-111.ec2.internal node True ip-172-20-40-24.ec2.internal master True ip-172-20-62-139.ec2.internal node True Note: If you ignore the message Cluster is starting. It should be ready in a few minutes. and validate too early, you\u2019ll get an error. Wait a little longer for the nodes to launch, and the validate step will return without error. $ kops validate cluster Validating cluster colors.k8s.local unexpected error during validation: error listing nodes: Get https://api-colors-k8s-local-71cb48-202595039.us-east-1.elb.amazonaws.com/api/v1/nodes: EOF Finally, you can see your Kubernetes nodes with kubectl: $ kubectl get nodes NAME STATUS ROLES AGE VERSION ip-172-20-34-111.ec2.internal Ready node 2h v1.9.3 ip-172-20-40-24.ec2.internal Ready master 2h v1.9.3 ip-172-20-62-139.ec2.internal Ready node 2h v1.9.3 Kubernetes Dashboard Excellent. We have a working Kubernetes cluster deployed on AWS. At this point, we can deploy lots of things, such as Dask and Jupyter. For demonstration, we\u2019ll launch the Kubernetes Dashboard. Think UI instead of command line for managing Kubernetes clusters and applications. Here\u2019s a YouTube video illustrating how to install the Kubernetes Dashboard: kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml secret \"kubernetes-dashboard-certs\" created serviceaccount \"kubernetes-dashboard\" created role.rbac.authorization.k8s.io \"kubernetes-dashboard-minimal\" created rolebinding.rbac.authorization.k8s.io \"kubernetes-dashboard-minimal\" created deployment.apps \"kubernetes-dashboard\" created service \"kubernetes-dashboard\" created You can see that various items were created, including the kubernetes-dashboard service and app. If the dashboard was created, how do we view it? Easy. Let\u2019s get the AWS hostname: $ kubectl cluster-info Kubernetes master is running at https://api-ramhiser-k8s-local-71cb48-202595039.us-east-1.elb.amazonaws.com KubeDNS is running at https://api-ramhiser-k8s-local-71cb48-202595039.us-east-1.elb.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. With this hostname, open your browser to https://api-ramhiser-k8s-local-71cb48-202595039.us-east-1.elb.amazonaws.com/ui. (You\u2019ll need to replace the hostname with yours). Alternatively, you can access the Dashboard UI via a proxy: kubectl proxy Starting to serve on 127.0.0.1:8001 https://api-colors-k8s-local-inoltk-1851277883.us-east-2.elb.amazonaws.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login login password nyY0Wm0ocm63cea1TnkA9G0cZkD3vEkd admin token XPjiuCWjRGM7ScVbmIoWtUU3ljsHnt04 Adding team member is kubernetes project https://itnext.io/let-you-team-members-use-kubernetes-bf2ebd0be717 helmins() { kubectl -n kube-system create serviceaccount tiller kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller helm init --service-account=tiller } helmdel() { kubectl -n kube-system delete deployment tiller-deploy kubectl delete clusterrolebinding tiller kubectl -n kube-system delete serviceaccount tiller } kubectl port-forward nonexistent-labradoodle-colors-helm-7cf6d7f88d-66dh5 8080:80 to get passs kops get secrets kube --type secret -oplaintext to get token kops get secrets admin --type secret -oplaintext To use kubectl in insecure mod kubectl --insecure-skip-tls-verify --context=colors.k8s.local get nodes","title":"Setup-Kubernetes"},{"location":"Setup-Kubernetes/#up-a-kubernetes-cluster-on-aws-in-5-minutes","text":"Kubernetes is like magic. It is a system for working with containerized applications: deployment, scaling, management, service discovery, magic. Think Docker at scale with little hassle. Despite the power of Kubernetes though, I find the official guide for setting up Kubernetes on AWS a bit overwhelming, so I wrote a simpler version to get started. As a side note, AWS introduced a new serviced called A mazon Elastic Container Service for Kubernetes \u2013 EKS for short. But it\u2019s still in Preview mode. Before we begin, here\u2019s a YouTube video demonstrating how to set up a Kubernetes Cluster on AWS following the instructions below:","title":"Up a Kubernetes Cluster on AWS in 5 Minutes"},{"location":"Setup-Kubernetes/#prerequisites","text":"Before setting up the Kubernetes cluster, you\u2019ll need an AWS account and an installation of the AWS Command Line Interface . Make sure to configure the AWS CLI to use your access key ID and secret access key: aws configure AWS Access Key ID [None]: your aws access key AWS Secret Access Key [None]: your aws secret key Default region name [None]: us-east-1 Default output format [None]: Installing kops + kubectl Now, to get started, let\u2019s install two Kubernetes CLI utilities: Kubernetes Operations, kops Kubernetes command-line tool, kubectl On Mac OS X, we\u2019ll use brew to install. If you\u2019re on Linux, see the official Kops installation guide.","title":"Prerequisites"},{"location":"Setup-Kubernetes/#setting-up-the-kubernetes-cluster","text":"Easy enough. Now, let\u2019s set up the Kubernetes cluster. The first thing we need to do is create an S3 bucket for kops to use to store the state of the Kubernetes cluster and its configuration. We\u2019ll use the bucket name colors-kops-state-store. $ aws s3api create-bucket --bucket colors-kops-state-store --region us-east-2 --create-bucket-configuration LocationConstraint=us-east-2 After creating the colors-kops-state-store bucket, let\u2019s enable versioning to revert or recover a previous state store. $ aws s3api put-bucket-versioning --bucket colors-kops-state-store --versioning-configuration Status=Enabled Before creating the cluster, let\u2019s set two environment variables: KOPS_CLUSTER_NAME and KOPS_STATE_STORE. For safe keeping you should add the following to your ~/.bash_profile or ~/.bashrc configs (or whatever the equivalent is if you don\u2019t use bash). export KOPS_CLUSTER_NAME=colors.k8s.local export KOPS_STATE_STORE=s3://colors-kops-state-store kops export kubecfg --state s3://colors-kops-state-store --name=colors.k8s.local You don\u2019t HAVE TO set the environment variables, but they are useful and referenced by kops commands. For example, see kops create cluster --help . If the the Kubernetes cluster name ends with k8s.local, Kubernetes will create a gossip-based cluster. Now, to generate the cluster configuration: $ kops create cluster --node-count=1 --node-size=t2.medium --zones=us-east-2b Note: this line doesn\u2019t launch the AWS EC2 instances. It simply creates the configuration and writes to the s3://colors-kops-state-store bucket we created above. In our example, we\u2019re creating 2 t2.medium EC2 work nodes in addition to a c4.large master instance (default). $ kops edit cluster Alternatively, you can name the cluster by appending --name to the command: $ kops create cluster --node-count=1 --node-size=t2.medium --zones=us-east-1a --name chubby-bunnies Now that we\u2019ve generated a cluster configuration, we can edit its description before launching the instances. The config is loaded from s3://colors-kops-state-store. You can change the editor used to edit the config by setting $EDITOR or $KUBE_EDITOR. For instance, in my ~/.bashrc, I have export KUBE_EDITOR=emacs. Time to build the cluster. This takes a few minutes to boot the EC2 instances and download the Kubernetes components. kops update cluster --name ${KOPS_CLUSTER_NAME} --yes After waiting a bit, let\u2019s validate the cluster to ensure the master + 2 nodes have launched. $ kops validate cluster Validating cluster colors.k8s.local INSTANCE GROUPS NAME ROLE MACHINETYPE MIN MAX SUBNETS master-us-east-1a Master c4.large 1 1 us-east-1a nodes Node t2.medium 2 2 us-east-1a NODE STATUS NAME ROLE READY ip-172-20-34-111.ec2.internal node True ip-172-20-40-24.ec2.internal master True ip-172-20-62-139.ec2.internal node True Note: If you ignore the message Cluster is starting. It should be ready in a few minutes. and validate too early, you\u2019ll get an error. Wait a little longer for the nodes to launch, and the validate step will return without error. $ kops validate cluster Validating cluster colors.k8s.local unexpected error during validation: error listing nodes: Get https://api-colors-k8s-local-71cb48-202595039.us-east-1.elb.amazonaws.com/api/v1/nodes: EOF Finally, you can see your Kubernetes nodes with kubectl: $ kubectl get nodes NAME STATUS ROLES AGE VERSION ip-172-20-34-111.ec2.internal Ready node 2h v1.9.3 ip-172-20-40-24.ec2.internal Ready master 2h v1.9.3 ip-172-20-62-139.ec2.internal Ready node 2h v1.9.3","title":"Setting Up the Kubernetes Cluster"},{"location":"Setup-Kubernetes/#kubernetes-dashboard","text":"Excellent. We have a working Kubernetes cluster deployed on AWS. At this point, we can deploy lots of things, such as Dask and Jupyter. For demonstration, we\u2019ll launch the Kubernetes Dashboard. Think UI instead of command line for managing Kubernetes clusters and applications. Here\u2019s a YouTube video illustrating how to install the Kubernetes Dashboard: kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml secret \"kubernetes-dashboard-certs\" created serviceaccount \"kubernetes-dashboard\" created role.rbac.authorization.k8s.io \"kubernetes-dashboard-minimal\" created rolebinding.rbac.authorization.k8s.io \"kubernetes-dashboard-minimal\" created deployment.apps \"kubernetes-dashboard\" created service \"kubernetes-dashboard\" created You can see that various items were created, including the kubernetes-dashboard service and app. If the dashboard was created, how do we view it? Easy. Let\u2019s get the AWS hostname: $ kubectl cluster-info Kubernetes master is running at https://api-ramhiser-k8s-local-71cb48-202595039.us-east-1.elb.amazonaws.com KubeDNS is running at https://api-ramhiser-k8s-local-71cb48-202595039.us-east-1.elb.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. With this hostname, open your browser to https://api-ramhiser-k8s-local-71cb48-202595039.us-east-1.elb.amazonaws.com/ui. (You\u2019ll need to replace the hostname with yours). Alternatively, you can access the Dashboard UI via a proxy: kubectl proxy Starting to serve on 127.0.0.1:8001 https://api-colors-k8s-local-inoltk-1851277883.us-east-2.elb.amazonaws.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login login password nyY0Wm0ocm63cea1TnkA9G0cZkD3vEkd admin token XPjiuCWjRGM7ScVbmIoWtUU3ljsHnt04","title":"Kubernetes Dashboard"},{"location":"Setup-Kubernetes/#adding-team-member-is-kubernetes-project","text":"https://itnext.io/let-you-team-members-use-kubernetes-bf2ebd0be717 helmins() { kubectl -n kube-system create serviceaccount tiller kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller helm init --service-account=tiller } helmdel() { kubectl -n kube-system delete deployment tiller-deploy kubectl delete clusterrolebinding tiller kubectl -n kube-system delete serviceaccount tiller } kubectl port-forward nonexistent-labradoodle-colors-helm-7cf6d7f88d-66dh5 8080:80 to get passs kops get secrets kube --type secret -oplaintext to get token kops get secrets admin --type secret -oplaintext","title":"Adding team member is kubernetes project"},{"location":"Setup-Kubernetes/#to-use-kubectl-in-insecure-mod","text":"kubectl --insecure-skip-tls-verify --context=colors.k8s.local get nodes","title":"To use kubectl in insecure mod"},{"location":"coin&address/","text":"Color Coin Color coin configuration in color-sdk Fork the color-sdk github repo https://github.com/RNSSolution/colors-sdk Navigate to types folder, open staking.go file Now to change the default denom name (coin name), change the value of variable DefaultBondDenom to the desired coin name i.e color . coin minting, inflation rate will be updated soon.","title":"coin"},{"location":"coin&address/#color-coin","text":"","title":"Color Coin"},{"location":"coin&address/#color-coin-configuration-in-color-sdk","text":"Fork the color-sdk github repo https://github.com/RNSSolution/colors-sdk Navigate to types folder, open staking.go file Now to change the default denom name (coin name), change the value of variable DefaultBondDenom to the desired coin name i.e color .","title":"Color coin configuration in color-sdk"},{"location":"coin&address/#coin-minting-inflation-rate-will-be-updated-soon","text":"","title":"coin minting, inflation rate will be updated soon."},{"location":"color-wallet/","text":"Color Wallet To build new image to color wallet docker run -v /home/faisalnaveed/goApps/src/github.com/RNSSolution/start.sh:/usr/src/app/start.sh -p 9080:9080 -d rnssolutions/colorwallet:v0.3","title":"color-wallet"},{"location":"color-wallet/#color-wallet","text":"","title":"Color Wallet"},{"location":"color-wallet/#to-build-new-image-to-color-wallet","text":"docker run -v /home/faisalnaveed/goApps/src/github.com/RNSSolution/start.sh:/usr/src/app/start.sh -p 9080:9080 -d rnssolutions/colorwallet:v0.3","title":"To build new image to color wallet"},{"location":"explorer-k8s-deployment/","text":"Deployment of explorer on k8s create secrets To pass environnement variables to explorer container we have to pass secrets to k8s. run this command kubectl create secret generic explorer-settings --from-file=./settings.json --insecure-skip-tls-verify Secrets of mongodb url and root rrl are added in yaml file. For this run following command kubectl apply -f ./secrets.yaml --insecure-skip-tls-verify to start deployment run following commands kubectl delete -f recipes/explorer.yaml --insecure-skip-tls-verify Docker Deployment of explorer Production docker run -d -e ROOT_URL=http://localhost/ -e MONGO_URL='mongodb://admin123:admin123@ds359077.mlab.com:59077/colorplatform' -e METEOR_SETTINGS=\"$(cat settings.json)\" -p 80:3000 rnssolutions/explorer:release1 To build explore in production following site is reference https://github.com/jshimko/meteor-launchpad environment variable export MONGO_URL='mongodb://admin123:admin123@ds359077.mlab.com:59077/colorplatform' export ROOT_URL='localhost' To build docker file docker run -d \\ -e ROOT_URL=http://localhost/ \\ -e MONGO_URL='mongodb://admin123:admin123@ds359077.mlab.com:59077/colorplatform' \\ -e METEOR_SETTINGS=\"$(cat settings.json)\" \\ -p 80:3000 \\ rnssolution/explorer","title":"explorer-k8s-deployment"},{"location":"explorer-k8s-deployment/#deployment-of-explorer-on-k8s","text":"","title":"Deployment of explorer on k8s"},{"location":"explorer-k8s-deployment/#create-secrets","text":"To pass environnement variables to explorer container we have to pass secrets to k8s. run this command kubectl create secret generic explorer-settings --from-file=./settings.json --insecure-skip-tls-verify Secrets of mongodb url and root rrl are added in yaml file. For this run following command kubectl apply -f ./secrets.yaml --insecure-skip-tls-verify to start deployment run following commands kubectl delete -f recipes/explorer.yaml --insecure-skip-tls-verify","title":"create secrets"},{"location":"explorer-k8s-deployment/#docker-deployment-of-explorer-production","text":"docker run -d -e ROOT_URL=http://localhost/ -e MONGO_URL='mongodb://admin123:admin123@ds359077.mlab.com:59077/colorplatform' -e METEOR_SETTINGS=\"$(cat settings.json)\" -p 80:3000 rnssolutions/explorer:release1","title":"Docker Deployment of explorer Production"},{"location":"explorer-k8s-deployment/#to-build-explore-in-production","text":"following site is reference https://github.com/jshimko/meteor-launchpad environment variable export MONGO_URL='mongodb://admin123:admin123@ds359077.mlab.com:59077/colorplatform' export ROOT_URL='localhost'","title":"To build explore in production"},{"location":"explorer-k8s-deployment/#to-build-docker-file","text":"docker run -d \\ -e ROOT_URL=http://localhost/ \\ -e MONGO_URL='mongodb://admin123:admin123@ds359077.mlab.com:59077/colorplatform' \\ -e METEOR_SETTINGS=\"$(cat settings.json)\" \\ -p 80:3000 \\ rnssolution/explorer","title":"To build docker file"},{"location":"nginx.deployment.k8s/","text":"Nginx Deployment on k8s Nginx is service is forward our requests to other services in the k8s. To deploy nginx first create secrets kubectl create secret generic nginx-conf --from-file=./nginx.conf --insecure-skip-tls-verify then deploy nginx on k8s kubectl create secret generic nginx-conf --from-file=./nginx.conf --insecure-skip-tls-verify","title":"nginx.deployment.k8s"},{"location":"nginx.deployment.k8s/#nginx-deployment-on-k8s","text":"Nginx is service is forward our requests to other services in the k8s. To deploy nginx first create secrets kubectl create secret generic nginx-conf --from-file=./nginx.conf --insecure-skip-tls-verify then deploy nginx on k8s kubectl create secret generic nginx-conf --from-file=./nginx.conf --insecure-skip-tls-verify","title":"Nginx Deployment on k8s"},{"location":"npm-packages/","text":"Color npm Packages Currently there are two npm packages of Color platform Color-keys Color-ledger 1. Color-keys Color-Keys package provides following functionalities to developers. * Generate new Wallet (pubkey,privkey,address). * Generate wallet from seed. * Sign message with wallet private key. Color-keys package was initially forked from cosmos-keys npm package. Now to generate color address instead of cosmos we had to change wallet address prefix. So, to change that: * Go to source folder * Open cosmos-keys.ts file * Move to line 61 and change the address prefix to desired prefix i.e color * Now change the name and version of the package from package.json file. * Publish the updated package to npm packages, using --access public tag. 2. Color-Legder This package helps interfacing with Color Ledger App. This package was also forked from cosmos ledger package. Following changes are made in it to make it run smoothly with color platform and color ledger app. * Navigate to cosmos-ledger.ts in the src folder. * On line #2 import color-keys package instead of cosmos-keys package. * Now on line #23 change the address prefix from cosmos to color . * On line # 107 there is a check on the ledger app name, change it to color . Now change the name and version of the package from package.json file.Publish the updated package to npm packages, using --access public tag.","title":"npm-packages"},{"location":"npm-packages/#color-npm-packages","text":"Currently there are two npm packages of Color platform Color-keys Color-ledger","title":"Color npm Packages"},{"location":"npm-packages/#1-color-keys","text":"Color-Keys package provides following functionalities to developers. * Generate new Wallet (pubkey,privkey,address). * Generate wallet from seed. * Sign message with wallet private key. Color-keys package was initially forked from cosmos-keys npm package. Now to generate color address instead of cosmos we had to change wallet address prefix. So, to change that: * Go to source folder * Open cosmos-keys.ts file * Move to line 61 and change the address prefix to desired prefix i.e color * Now change the name and version of the package from package.json file. * Publish the updated package to npm packages, using --access public tag.","title":"1. Color-keys"},{"location":"npm-packages/#2color-legder","text":"This package helps interfacing with Color Ledger App. This package was also forked from cosmos ledger package. Following changes are made in it to make it run smoothly with color platform and color ledger app. * Navigate to cosmos-ledger.ts in the src folder. * On line #2 import color-keys package instead of cosmos-keys package. * Now on line #23 change the address prefix from cosmos to color . * On line # 107 there is a check on the ledger app name, change it to color . Now change the name and version of the package from package.json file.Publish the updated package to npm packages, using --access public tag.","title":"2.Color-Legder"},{"location":"sdkconfigration/","text":"SDK CONFIGURATION Cloning the repository To configure cosmos sdk perform the following steps. Fork the repository form the main sdk repository [https://github.com/cosmos/cosmos-sdk](https://github.com/cosmos/cosmos-sdk) Change the name to colors sdk of the repository using settings in github Updating the mod file Mod file in project ensure the version management. To reconfigure the mod file perform the following steps. To inside the colors project directory and open terminal here, run the following commands go mod edit -replace github.com/cosmos/cosmos-sdk => github.com/RNSSolution/cosmos-sdk v0.28.2-0.20190622092459-7b5e6cee0787 make sure the commit number and version number in go mod edit make the project make install Making changes in sdk project Checkout the version you specfied in go mod edit. pull the following command to add tag git tag v0.28.3 Push new changes to github get time stamp of git commit git show --no-patch --no-notes --pretty='%cd' [place commit hash here] replace the time stamp and git hash in go mod file by building hte following file v0.28.2-0.20190622092459-7b5e6cee078","title":"sdk"},{"location":"sdkconfigration/#sdk-configuration","text":"","title":"SDK CONFIGURATION"},{"location":"sdkconfigration/#cloning-the-repository","text":"To configure cosmos sdk perform the following steps. Fork the repository form the main sdk repository [https://github.com/cosmos/cosmos-sdk](https://github.com/cosmos/cosmos-sdk) Change the name to colors sdk of the repository using settings in github","title":"Cloning the repository"},{"location":"sdkconfigration/#updating-the-mod-file","text":"Mod file in project ensure the version management. To reconfigure the mod file perform the following steps. To inside the colors project directory and open terminal here, run the following commands go mod edit -replace github.com/cosmos/cosmos-sdk => github.com/RNSSolution/cosmos-sdk v0.28.2-0.20190622092459-7b5e6cee0787 make sure the commit number and version number in go mod edit make the project make install","title":"Updating the mod file"},{"location":"sdkconfigration/#making-changes-in-sdk-project","text":"Checkout the version you specfied in go mod edit. pull the following command to add tag git tag v0.28.3 Push new changes to github get time stamp of git commit git show --no-patch --no-notes --pretty='%cd' [place commit hash here] replace the time stamp and git hash in go mod file by building hte following file v0.28.2-0.20190622092459-7b5e6cee078","title":"Making changes in sdk project"}]}